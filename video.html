<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Smart Trimmer (Client-Side)</title>
    
    <!-- COI Service Worker: Enables High-Performance Headers automatically for GitHub Pages/Netlify -->
    <script src="https://unpkg.com/coi-serviceworker/coi-serviceworker.js"></script>

    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- FFmpeg (Video Processing) -->
    <script src="https://unpkg.com/@ffmpeg/ffmpeg@0.12.7/dist/ffmpeg.min.js"></script>
    <script src="https://unpkg.com/@ffmpeg/util@0.12.1/dist/index.min.js"></script>
    
    <!-- Transformers.js (AI Transcription) -->
    <script type="module" src="https://cdn.jsdelivr.net/npm/@xenova/transformers@2.14.0"></script>
    
    <style>
        body { font-family: 'Inter', sans-serif; background-color: #020617; color: #f8fafc; }
        
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: #0f172a; }
        ::-webkit-scrollbar-thumb { background: #334155; border-radius: 3px; }
        ::-webkit-scrollbar-thumb:hover { background: #475569; }

        .word-span {
            cursor: pointer;
            padding: 2px 4px;
            margin: 0 1px 4px 1px;
            border-radius: 4px;
            display: inline-block;
            transition: all 0.15s ease;
            font-size: 1.05rem;
            line-height: 1.6;
            border: 1px solid transparent;
            user-select: none;
        }
        
        .word-dimmed { color: #64748b; background: rgba(30, 41, 59, 0.3); }
        .word-dimmed:hover { background: rgba(30, 41, 59, 0.8); }

        .word-selected { 
            background-color: #2563eb; 
            color: #ffffff; 
            border-color: #3b82f6;
            box-shadow: 0 2px 4px rgba(37, 99, 235, 0.2);
        }
        
        .word-playback {
            border-bottom: 2px solid #ef4444;
        }

        .animate-shimmer {
            background: linear-gradient(90deg, #2563eb 25%, #60a5fa 50%, #2563eb 75%);
            background-size: 200% 100%;
            animation: shimmer 2s infinite linear;
        }
        @keyframes shimmer { 0% { background-position: -200% 0; } 100% { background-position: 200% 0; } }
    </style>
</head>
<body class="h-screen flex flex-col overflow-hidden selection:bg-blue-500 selection:text-white">

    <!-- Top Bar -->
    <header class="h-14 border-b border-slate-800 bg-slate-900/80 backdrop-blur-md flex items-center justify-between px-4 shrink-0 z-20">
        <div class="flex items-center gap-3">
            <div class="w-8 h-8 bg-gradient-to-br from-blue-600 to-indigo-600 rounded-lg flex items-center justify-center shadow-lg shadow-blue-500/20">
                <svg class="w-4 h-4 text-white" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2.5"><path stroke-linecap="round" stroke-linejoin="round" d="M13 10V3L4 14h7v7l9-11h-7z"/></svg>
            </div>
            <div>
                <h1 class="font-bold text-sm tracking-wide text-white">AI SMART TRIM</h1>
                <p class="text-[10px] text-slate-400 font-mono">100% CLIENT SIDE • <span id="status-badge" class="text-yellow-500">LOADING ENGINE...</span></p>
            </div>
        </div>
        
        <div class="flex items-center gap-3">
            <button id="preview-btn" disabled class="hidden md:flex items-center gap-2 text-xs font-semibold text-slate-400 hover:text-white transition-colors disabled:opacity-30">
                <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 24 24"><path d="M8 5v14l11-7z"/></svg>
                Preview Selection
            </button>
            <button id="export-btn" disabled class="bg-slate-800 text-slate-400 px-5 py-2 rounded-md text-xs font-bold uppercase tracking-wider transition-all disabled:opacity-50 disabled:cursor-not-allowed hover:bg-blue-600 hover:text-white hover:shadow-lg hover:shadow-blue-500/30 flex items-center gap-2">
                Export Video
                <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"/></svg>
            </button>
        </div>
    </header>

    <!-- Main Workspace -->
    <main class="flex-1 flex overflow-hidden">
        
        <!-- Left Panel: Video Preview -->
        <div class="w-full md:w-[45%] lg:w-[40%] flex flex-col bg-black relative border-r border-slate-800">
            <div class="flex-1 flex items-center justify-center relative bg-[url('data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PGNpcmNsZSBjeD0iMSIgY3k9IjEiIHI9IjEiIGZpbGw9InJnYmEoMjU1LDI1NSwyNTUsMC4wNSkiLz48L3N2Zz4=')]">
                <video id="main-video" class="max-h-full max-w-full shadow-2xl" controls playsinline></video>
                
                <!-- Drop Zone -->
                <div id="upload-overlay" class="absolute inset-0 flex flex-col items-center justify-center bg-slate-900/95 z-10 transition-all duration-300">
                    <div class="group relative cursor-pointer" onclick="document.getElementById('file-input').click()">
                        <div class="w-24 h-24 bg-slate-800 rounded-3xl flex items-center justify-center border-2 border-slate-700 group-hover:border-blue-500 group-hover:scale-105 transition-all duration-300 shadow-2xl">
                            <svg class="w-10 h-10 text-slate-500 group-hover:text-blue-400 transition-colors" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"/></svg>
                        </div>
                        <div class="absolute -bottom-12 left-1/2 -translate-x-1/2 w-64 text-center">
                            <p class="text-sm font-semibold text-white">Click to Upload Video</p>
                            <p class="text-[10px] text-slate-500 uppercase tracking-wide mt-1">Local Processing • No Uploads</p>
                        </div>
                    </div>
                    <input type="file" id="file-input" class="hidden" accept="video/*">
                </div>

                <!-- Processing UI -->
                <div id="processing-overlay" class="hidden absolute inset-0 flex flex-col items-center justify-center bg-slate-900/95 z-20 backdrop-blur-sm">
                    <div class="w-72">
                        <div class="flex justify-between items-end mb-2">
                            <span id="process-step" class="text-xs font-bold text-blue-400 uppercase tracking-wider">Initializing...</span>
                            <span id="process-percent" class="text-2xl font-mono font-bold text-white">0%</span>
                        </div>
                        <div class="h-1.5 bg-slate-800 rounded-full overflow-hidden">
                            <div id="process-bar" class="h-full bg-blue-600 w-0 transition-all duration-300"></div>
                        </div>
                        <p class="text-[10px] text-slate-500 mt-4 text-center font-mono">DO NOT CLOSE TAB</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Right Panel: Smart Transcript -->
        <div class="w-full md:w-[55%] lg:w-[60%] flex flex-col bg-slate-950">
            <!-- Toolbar -->
            <div class="h-12 border-b border-slate-800 flex items-center justify-between px-6 bg-slate-900/50">
                <div class="flex items-center gap-4">
                    <span class="text-[10px] font-bold uppercase tracking-widest text-slate-500">Transcript</span>
                    <div class="text-[10px] text-slate-400 bg-slate-800 px-2 py-1 rounded">
                        <span class="text-blue-400 font-bold">LMB</span> Select Start &nbsp;•&nbsp; <span class="text-blue-400 font-bold">Shift+Click</span> Select End
                    </div>
                </div>
                <div class="text-[10px] text-slate-500">
                    <span id="word-count">0</span> words
                </div>
            </div>

            <!-- Content -->
            <div id="transcript-container" class="flex-1 overflow-y-auto p-6 md:p-8 text-left select-none outline-none" tabindex="0">
                <div class="h-full flex flex-col items-center justify-center text-slate-600 space-y-3">
                    <p class="italic">Waiting for media...</p>
                </div>
            </div>
        </div>
    </main>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.14.0';

        // --- Config ---
        env.allowLocalModels = false;
        env.useBrowserCache = true;

        // --- Globals ---
        const { createFFmpeg, fetchFile } = FFmpeg;
        let ffmpeg = null;
        let transcriber = null;
        let audioContext = null;
        let transcriptData = []; 
        let currentSelection = { startIdx: null, endIdx: null };
        let isPreviewing = false;

        // --- DOM Elements ---
        const els = {
            fileInput: document.getElementById('file-input'),
            uploadOverlay: document.getElementById('upload-overlay'),
            processingOverlay: document.getElementById('processing-overlay'),
            processBar: document.getElementById('process-bar'),
            processStep: document.getElementById('process-step'),
            processPercent: document.getElementById('process-percent'),
            transcript: document.getElementById('transcript-container'),
            video: document.getElementById('main-video'),
            exportBtn: document.getElementById('export-btn'),
            previewBtn: document.getElementById('preview-btn'),
            statusBadge: document.getElementById('status-badge'),
            wordCount: document.getElementById('word-count')
        };

        // --- Init ---
        async function initEngines() {
            try {
                // 1. Init FFmpeg
                if (!ffmpeg) {
                    ffmpeg = createFFmpeg({ 
                        log: false,
                        corePath: 'https://unpkg.com/@ffmpeg/core@0.12.6/dist/ffmpeg-core.js'
                    });
                    await ffmpeg.load();
                }

                // 2. Init AI
                if (!transcriber) {
                    transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');
                }

                els.statusBadge.textContent = "READY";
                els.statusBadge.className = "text-green-400";
                return true;
            } catch (e) {
                console.error(e);
                els.statusBadge.textContent = "ERROR - See Console";
                els.statusBadge.className = "text-red-500";
                alert("Failed to load engines. If running locally, use a local server (http-server).");
                return false;
            }
        }

        // --- File Handling ---
        els.fileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;

            els.video.src = URL.createObjectURL(file);
            els.uploadOverlay.classList.add('hidden');
            els.processingOverlay.classList.remove('hidden');
            els.transcript.innerHTML = '';
            
            // Start Process
            try {
                updateProgress("Loading Engines...", 10);
                await initEngines();

                updateProgress("Extracting Audio...", 30);
                const audioData = await extractAudio(file);

                updateProgress("Decoding Audio...", 50);
                const audioBuffer = await decodeAudio(audioData);

                updateProgress("Transcribing...", 70);
                const output = await transcriber(audioBuffer, {
                    chunk_length_s: 30, 
                    stride_length_s: 5, 
                    return_timestamps: true
                });

                updateProgress("Finalizing...", 95);
                renderTranscript(output);
                
                els.processingOverlay.classList.add('hidden');

            } catch (err) {
                console.error(err);
                alert("Processing failed. Please check console.");
                els.processingOverlay.classList.add('hidden');
                els.uploadOverlay.classList.remove('hidden');
            }
        });

        // --- Core Functions ---
        async function extractAudio(file) {
            ffmpeg.FS('writeFile', 'input.mp4', await fetchFile(file));
            await ffmpeg.run('-i', 'input.mp4', '-vn', '-ac', '1', '-ar', '16000', 'audio.wav');
            return ffmpeg.FS('readFile', 'audio.wav');
        }

        async function decodeAudio(u8Array) {
            if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            const decoded = await audioContext.decodeAudioData(u8Array.buffer);
            return decoded.getChannelData(0);
        }

        function renderTranscript(output) {
            transcriptData = [];
            let globalIdx = 0;
            const chunks = output.chunks || [];

            chunks.forEach(chunk => {
                const text = chunk.text.trim();
                if (!text) return;
                
                // Estimate word timestamps
                const words = text.split(/\s+/);
                const start = chunk.timestamp[0];
                const end = chunk.timestamp[1];
                const duration = end - start;
                const wordDur = duration / words.length;

                words.forEach((w, i) => {
                    const wStart = start + (i * wordDur);
                    const wEnd = wStart + wordDur;
                    
                    transcriptData.push({ text: w, start: wStart, end: wEnd, idx: globalIdx });
                    
                    const span = document.createElement('span');
                    span.textContent = w;
                    span.className = 'word-span word-dimmed';
                    span.dataset.idx = globalIdx;
                    span.onclick = (e) => handleWordClick(globalIdx, e);
                    
                    els.transcript.appendChild(span);
                    els.transcript.appendChild(document.createTextNode(' '));
                    globalIdx++;
                });
            });

            els.wordCount.textContent = globalIdx;
            
            // Auto-Select All
            if (globalIdx > 0) {
                currentSelection = { startIdx: 0, endIdx: globalIdx - 1 };
                updateSelectionUI();
            }
        }

        // --- Interaction ---
        function handleWordClick(idx, e) {
            if (e.shiftKey && currentSelection.startIdx !== null) {
                // Range Selection
                if (idx < currentSelection.startIdx) {
                    currentSelection.endIdx = currentSelection.startIdx; // Swap if backward selection
                    currentSelection.startIdx = idx;
                } else {
                    currentSelection.endIdx = idx;
                }
            } else {
                // New Selection
                currentSelection.startIdx = idx;
                currentSelection.endIdx = idx;
            }
            
            els.video.currentTime = transcriptData[currentSelection.startIdx].start;
            updateSelectionUI();
        }

        function updateSelectionUI() {
            const spans = document.querySelectorAll('.word-span');
            spans.forEach(span => {
                const i = parseInt(span.dataset.idx);
                const isSelected = i >= currentSelection.startIdx && i <= currentSelection.endIdx;
                span.className = isSelected ? 'word-span word-selected' : 'word-span word-dimmed';
            });
            
            const hasSelection = currentSelection.startIdx !== null;
            els.exportBtn.disabled = !hasSelection;
            els.previewBtn.disabled = !hasSelection;
            
            if (hasSelection) {
                const dur = transcriptData[currentSelection.endIdx].end - transcriptData[currentSelection.startIdx].start;
                els.exportBtn.innerHTML = `Export Clip (${dur.toFixed(1)}s)`;
            }
        }

        // --- Preview Logic ---
        els.previewBtn.addEventListener('click', () => {
            if (isPreviewing) {
                els.video.pause();
                return;
            }
            
            const startT = transcriptData[currentSelection.startIdx].start;
            const endT = transcriptData[currentSelection.endIdx].end;
            
            els.video.currentTime = startT;
            els.video.play();
            isPreviewing = true;
            els.previewBtn.innerHTML = `<span class="text-white">Stop Preview</span>`;
            
            // Auto stop
            const checkStop = setInterval(() => {
                if (els.video.currentTime >= endT || els.video.paused) {
                    els.video.pause();
                    clearInterval(checkStop);
                    isPreviewing = false;
                    els.previewBtn.innerHTML = `Preview Selection`;
                }
            }, 100);
        });

        // --- Export Logic ---
        els.exportBtn.addEventListener('click', async () => {
            const startT = transcriptData[currentSelection.startIdx].start;
            const endT = transcriptData[currentSelection.endIdx].end;
            const duration = endT - startT;

            const originalText = els.exportBtn.innerText;
            els.exportBtn.disabled = true;
            els.exportBtn.innerHTML = `<span class="animate-pulse">PROCESSING...</span>`;

            try {
                // Fast Stream Copy
                await ffmpeg.run(
                    '-ss', startT.toFixed(3),
                    '-i', 'input.mp4',
                    '-t', duration.toFixed(3),
                    '-c', 'copy',
                    'output.mp4'
                );

                const data = ffmpeg.FS('readFile', 'output.mp4');
                const url = URL.createObjectURL(new Blob([data.buffer], { type: 'video/mp4' }));
                
                const a = document.createElement('a');
                a.href = url;
                a.download = `smart_trim_${Date.now()}.mp4`;
                a.click();

                els.exportBtn.innerHTML = `<span class="text-green-400">DONE!</span>`;
                setTimeout(() => {
                    els.exportBtn.innerHTML = originalText;
                    els.exportBtn.disabled = false;
                }, 2000);
            } catch (e) {
                console.error(e);
                alert("Export failed. If using 'Copy' mode, keyframes might be an issue.");
                els.exportBtn.innerHTML = originalText;
                els.exportBtn.disabled = false;
            }
        });

        function updateProgress(text, percent) {
            els.processStep.textContent = text;
            els.processPercent.textContent = Math.round(percent) + '%';
            els.processBar.style.width = percent + '%';
        }

        // --- Auto-Initialize on Load (Fast Start) ---
        window.addEventListener('load', () => {
            initEngines(); 
        });

    </script>
</body>
</html>
